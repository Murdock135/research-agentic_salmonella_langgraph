{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac163d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparq.tools.python_repl.python_repl_tool import python_repl_tool\n",
    "from sparq.utils.helpers import get_llm\n",
    "from sparq.settings import Settings\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ca71d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def my_tool_function(input: str) -> str:\n",
    "    \"\"\"\n",
    "    A simple tool function that processes the input string and returns a formatted string.\n",
    "    \"\"\"\n",
    "    return f\"Processed input: {input}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba2c49c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = Settings()\n",
    "settings._load_env_variables(Path(\"../.env\"))\n",
    "\n",
    "breakpoint()\n",
    "if os.getenv(\"GEMINI_API_KEY\"):\n",
    "    model = \"gemini-2.0-flash\"\n",
    "    provider = \"google_genai\"\n",
    "    llm = get_llm(model=model, provider=provider)\n",
    "else:\n",
    "    raise ValueError(\"GEMINI_API_KEY is not set in the environment variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d971a880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent created successfully with python REPL tool\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    agent = create_react_agent(\n",
    "        model=llm,\n",
    "        tools=[my_tool_function, python_repl_tool]\n",
    "    )\n",
    "    print(\"Agent created successfully with python REPL tool\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating agent: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05591153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent output: {'messages': [HumanMessage(content='Use python to add two numbers: 3.9345 and 5.4345', additional_kwargs={}, response_metadata={}, id='091eeca7-4f0a-411b-b930-fb7ec8eed995'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'python_repl_tool', 'arguments': '{\"code\": \"print(3.9345 + 5.4345)\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--5c2ebb63-ea1b-4475-a2ab-df7b238637bc-0', tool_calls=[{'name': 'python_repl_tool', 'args': {'code': 'print(3.9345 + 5.4345)'}, 'id': '3a388404-99e8-45ca-b9eb-aa0f2fe18b5f', 'type': 'tool_call'}], usage_metadata={'input_tokens': 177, 'output_tokens': 23, 'total_tokens': 200, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='✓ Code executed successfully.\\nOutput:\\n9.369', name='python_repl_tool', id='1302a151-cba4-4c0d-b7c8-539ab55b67e2', tool_call_id='3a388404-99e8-45ca-b9eb-aa0f2fe18b5f', artifact=OutputSchema(output='9.369', error=None, namespace={}, success=True)), AIMessage(content='3.  9345 + 5.4345 = 9.369', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--c5cfd011-93f2-4e2a-b8d2-c83eaf9e4897-0', usage_metadata={'input_tokens': 220, 'output_tokens': 23, 'total_tokens': 243, 'input_token_details': {'cache_read': 0}})]}\n",
      "Type(output): <class 'langgraph.pregel.io.AddableValuesDict'>\n",
      "repr(output): {'messages': [HumanMessage(content='Use python to add two numbers: 3.9345 and 5.4345', additional_kwargs={}, response_metadata={}, id='091eeca7-4f0a-411b-b930-fb7ec8eed995'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'python_repl_tool', 'arguments': '{\"code\": \"print(3.9345 + 5.4345)\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--5c2ebb63-ea1b-4475-a2ab-df7b238637bc-0', tool_calls=[{'name': 'python_repl_tool', 'args': {'code': 'print(3.9345 + 5.4345)'}, 'id': '3a388404-99e8-45ca-b9eb-aa0f2fe18b5f', 'type': 'tool_call'}], usage_metadata={'input_tokens': 177, 'output_tokens': 23, 'total_tokens': 200, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='✓ Code executed successfully.\\nOutput:\\n9.369', name='python_repl_tool', id='1302a151-cba4-4c0d-b7c8-539ab55b67e2', tool_call_id='3a388404-99e8-45ca-b9eb-aa0f2fe18b5f', artifact=OutputSchema(output='9.369', error=None, namespace={}, success=True)), AIMessage(content='3.  9345 + 5.4345 = 9.369', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--c5cfd011-93f2-4e2a-b8d2-c83eaf9e4897-0', usage_metadata={'input_tokens': 220, 'output_tokens': 23, 'total_tokens': 243, 'input_token_details': {'cache_read': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    prompt = \"Use python to add two numbers: 3.9345 and 5.4345\"\n",
    "    input = {\"messages\": [{\"role\": \"user\", \"content\": prompt}]}\n",
    "    output = agent.invoke(input)\n",
    "    print(f\"Agent output: {output}\")\n",
    "\n",
    "    print(\"Type(output):\", type(output))\n",
    "    print(\"repr(output):\", repr(output))\n",
    "except Exception as e:\n",
    "    print(f\"Error running agent: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "927cbc1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.369"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3.9345 + 5.4345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68b51135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "information on the output from agent.invoke()\n",
      "Type(output): <class 'langgraph.pregel.io.AddableValuesDict'>\n",
      "repr(output): {'messages': [HumanMessage(content='Use python to add two numbers: 3.9345 and 5.4345', additional_kwargs={}, response_metadata={}, id='a62126e9-9970-49ec-b8cc-cbb4e30e4ca7'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'python_repl_tool', 'arguments': '{\"code\": \"print(3.9345 + 5.4345)\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--f21e11f9-98fa-46c6-b779-52d59cdbeb88-0', tool_calls=[{'name': 'python_repl_tool', 'args': {'code': 'print(3.9345 + 5.4345)'}, 'id': '9de84b79-44ef-489c-a20c-9c512a2babb3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 177, 'output_tokens': 23, 'total_tokens': 200, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='✓ Code executed successfully.\\nOutput:\\n9.369', name='python_repl_tool', id='7ad7fae7-b473-4da8-941a-6149536bb136', tool_call_id='9de84b79-44ef-489c-a20c-9c512a2babb3'), AIMessage(content='3.  9345 + 5.4345 = 9.369', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--4499c220-6510-40f7-88a5-525ab7894f7e-0', usage_metadata={'input_tokens': 220, 'output_tokens': 23, 'total_tokens': 243, 'input_token_details': {'cache_read': 0}})]}\n",
      "len(output): 1\n",
      "output.keys(): dict_keys(['messages'])\n",
      "\n",
      "type(output['messages']): <class 'list'>\n",
      "len(output['messages']): 4\n",
      "[HumanMessage(content='Use python to add two numbers: 3.9345 and 5.4345', additional_kwargs={}, response_metadata={}, id='a62126e9-9970-49ec-b8cc-cbb4e30e4ca7'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'python_repl_tool', 'arguments': '{\"code\": \"print(3.9345 + 5.4345)\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--f21e11f9-98fa-46c6-b779-52d59cdbeb88-0', tool_calls=[{'name': 'python_repl_tool', 'args': {'code': 'print(3.9345 + 5.4345)'}, 'id': '9de84b79-44ef-489c-a20c-9c512a2babb3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 177, 'output_tokens': 23, 'total_tokens': 200, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='✓ Code executed successfully.\\nOutput:\\n9.369', name='python_repl_tool', id='7ad7fae7-b473-4da8-941a-6149536bb136', tool_call_id='9de84b79-44ef-489c-a20c-9c512a2babb3'), AIMessage(content='3.  9345 + 5.4345 = 9.369', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--4499c220-6510-40f7-88a5-525ab7894f7e-0', usage_metadata={'input_tokens': 220, 'output_tokens': 23, 'total_tokens': 243, 'input_token_details': {'cache_read': 0}})]\n",
      "\n",
      "type(output['messages'][0]): <class 'langchain_core.messages.human.HumanMessage'>\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Use python to add two numbers: 3.9345 and 5.4345\n",
      "output['messages'][0].pretty_print(): None\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  python_repl_tool (9de84b79-44ef-489c-a20c-9c512a2babb3)\n",
      " Call ID: 9de84b79-44ef-489c-a20c-9c512a2babb3\n",
      "  Args:\n",
      "    code: print(3.9345 + 5.4345)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"information on the output from agent.invoke()\")\n",
    "print(\"Type(output):\", type(output))\n",
    "print(\"repr(output):\", repr(output))\n",
    "print(\"len(output):\", len(output))\n",
    "print(\"output.keys():\", output.keys())\n",
    "print()\n",
    "print(\"type(output['messages']):\", type(output[\"messages\"]))\n",
    "print(\"len(output['messages']):\", len(output[\"messages\"]))\n",
    "print(output['messages'])\n",
    "print()\n",
    "print(\"type(output['messages'][0]):\", type(output[\"messages\"][0]))\n",
    "print(\"output['messages'][0].pretty_print():\", output['messages'][0].pretty_print())\n",
    "print()\n",
    "print(output['messages'][1].pretty_print())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a36ab6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_call': {'name': 'python_repl_tool',\n",
       "  'arguments': '{\"code\": \"print(3.9345 + 5.4345)\"}'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['messages'][1].additional_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84e2378e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"code\": \"print(3.9345 + 5.4345)\"}'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['messages'][1].additional_kwargs['function_call']['arguments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31df962c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 'print(3.9345 + 5.4345)'}\n",
      "print(3.9345 + 5.4345)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.loads(output['messages'][1].additional_kwargs['function_call']['arguments']))\n",
    "\n",
    "# get the code\n",
    "code = json.loads(output['messages'][1].additional_kwargs['function_call']['arguments'])['code']\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "071ef1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m1\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    from multiprocessing.spawn import spawn_main; \u001b[31mspawn_main\u001b[0m\u001b[1;31m(tracker_fd=81, pipe_handle=90)\u001b[0m\n",
      "                                                  \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/Users/zayan/.local/share/uv/python/cpython-3.13.3-macos-aarch64-none/lib/python3.13/multiprocessing/spawn.py\"\u001b[0m, line \u001b[35m122\u001b[0m, in \u001b[35mspawn_main\u001b[0m\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \u001b[35m\"/Users/zayan/.local/share/uv/python/cpython-3.13.3-macos-aarch64-none/lib/python3.13/multiprocessing/spawn.py\"\u001b[0m, line \u001b[35m132\u001b[0m, in \u001b[35m_main\u001b[0m\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "\u001b[1;35mAttributeError\u001b[0m: \u001b[35mCan't get attribute 'simple_test' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m     process.terminate()\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     result = \u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcess worked: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.3-macos-aarch64-none/lib/python3.13/multiprocessing/queues.py:101\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m block \u001b[38;5;129;01mand\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    100\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._rlock:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m         res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m     \u001b[38;5;28mself\u001b[39m._sem.release()\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.3-macos-aarch64-none/lib/python3.13/multiprocessing/connection.py:216\u001b[39m, in \u001b[36m_ConnectionBase.recv_bytes\u001b[39m\u001b[34m(self, maxlength)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m maxlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m maxlength < \u001b[32m0\u001b[39m:\n\u001b[32m    215\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mnegative maxlength\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m buf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    218\u001b[39m     \u001b[38;5;28mself\u001b[39m._bad_message_length()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.3-macos-aarch64-none/lib/python3.13/multiprocessing/connection.py:430\u001b[39m, in \u001b[36mConnection._recv_bytes\u001b[39m\u001b[34m(self, maxsize)\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m     buf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    431\u001b[39m     size, = struct.unpack(\u001b[33m\"\u001b[39m\u001b[33m!i\u001b[39m\u001b[33m\"\u001b[39m, buf.getvalue())\n\u001b[32m    432\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m size == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.3-macos-aarch64-none/lib/python3.13/multiprocessing/connection.py:395\u001b[39m, in \u001b[36mConnection._recv\u001b[39m\u001b[34m(self, size, read)\u001b[39m\n\u001b[32m    393\u001b[39m remaining = size\n\u001b[32m    394\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m remaining > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m     chunk = \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    396\u001b[39m     n = \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[32m    397\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n == \u001b[32m0\u001b[39m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Diagnostic: Test basic multiprocessing\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "def simple_test(queue):\n",
    "    queue.put(\"Hello from subprocess\")\n",
    "\n",
    "queue = mp.Queue()\n",
    "process = mp.Process(target=simple_test, args=(queue,))\n",
    "process.start()\n",
    "process.join(timeout=5)\n",
    "\n",
    "if process.is_alive():\n",
    "    print(\"Process hung!\")\n",
    "    process.terminate()\n",
    "else:\n",
    "    result = queue.get()\n",
    "    print(f\"Process worked: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b6adf23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing basic function call...\n",
      "Success: ✓ Code executed successfully.\n",
      "Output:\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# Test basic function\n",
    "print(\"Testing basic function call...\")\n",
    "code = \"\"\"\n",
    "def foo(x: int) -> int:\n",
    "    return x + x\n",
    "\n",
    "x = 3\n",
    "print(foo(x))\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    result = python_repl_tool.invoke({\"code\": code, \"timeout\": 5})\n",
    "    print(f\"Success: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0afb2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Recursion with Fibonacci...\n",
      "Success: ✓ Code executed successfully.\n",
      "Output:\n",
      "fib(10): 55\n"
     ]
    }
   ],
   "source": [
    "# Test Fibonacci\n",
    "from sparq.tools.python_repl.python_repl_tool import python_repl_tool\n",
    "\n",
    "print(\"Testing Recursion with Fibonacci...\")\n",
    "code = \"\"\"\n",
    "def fib(n):\n",
    "    if n <= 0:\n",
    "        return 0\n",
    "    elif n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return fib(n-1) + fib(n-2)\n",
    "\n",
    "print(f\"fib(10): {fib(10)}\")\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    result = python_repl_tool.invoke({\"code\": code, \"timeout\": 30})\n",
    "    print(f\"Success: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6afdc050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Recursion with Fibonacci...\n",
      "Success: ✗ Execution failed.\n",
      "Error (QueueEmptyError): Result queue was empty.\n",
      "\n",
      "Traceback:\n",
      "\n",
      "Extra Context:\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Test Fibonacci\n",
    "from sparq.tools.python_repl.python_repl_tool import python_repl_tool\n",
    "\n",
    "print(\"Testing Recursion with Fibonacci...\")\n",
    "code = \"\"\"\n",
    "def fib(n):\n",
    "    if n <= 0:\n",
    "        return 0\n",
    "    elif n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return fib(n-1) + fib(n-2)\n",
    "\n",
    "print(f\"fib(10): {fib(10)}\")\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    result = python_repl_tool.invoke({\"code\": code, \"timeout\": 30})\n",
    "    print(f\"Success: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29ca3fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing NumPy execution directly...\n",
      "Success: ✓ Code executed successfully.\n",
      "Output:\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "# Test NumPy with detailed output\n",
    "from sparq.tools.python_repl.python_repl_tool import python_repl_tool\n",
    "\n",
    "print(\"Testing NumPy execution directly...\")\n",
    "code = \"\"\"\n",
    "import numpy as np\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "mean = arr.mean()\n",
    "std = arr.std()\n",
    "print(f\"Mean: {mean}, Std: {std}\")\n",
    "mean\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    result = python_repl_tool.invoke({\"code\": code, \"timeout\": 30})\n",
    "    print(f\"Success: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a79a54c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing variable persistence across executions...\n",
      "Execution 1 Success: ✓ Code executed successfully.\n",
      "Output:\n",
      "x is set to: 42\n",
      "Execution 2 Success: ✓ Code executed successfully.\n",
      "Output:\n",
      "x from previous execution is: 42\n",
      "y is: 52\n"
     ]
    }
   ],
   "source": [
    "# Test variable persistence across executions\n",
    "from sparq.tools.python_repl.python_repl_tool import python_repl_tool\n",
    "\n",
    "print(\"Testing variable persistence across executions...\")\n",
    "code1 = \"\"\"x = 42\n",
    "print(f\"x is set to: {x}\")\n",
    "\"\"\"\n",
    "code2 = \"\"\"print(f\"x from previous execution is: {x}\")\n",
    "y = x + 10\n",
    "print(f\"y is: {y}\")\n",
    "\"\"\" \n",
    "\n",
    "try:\n",
    "    result1 = python_repl_tool.invoke({\"code\": code1, \"persist_namespace\": True, \"timeout\": 30})\n",
    "    print(f\"Execution 1 Success: {result1}\")\n",
    "    \n",
    "    result2 = python_repl_tool.invoke({\"code\": code2, \"persist_namespace\": True, \"timeout\": 30})\n",
    "    print(f\"Execution 2 Success: {result2}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "383a3e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Example 1: Basic Arithmetic ===\n",
      "Final answer: 3.  9345 + 5.4345 = 9.369\n",
      "\n",
      "=== Example 2: Multi-Step Calculation ===\n",
      "Final answer: The average of the numbers is 45.0.\n",
      "\n",
      "=== Example 3: Using NumPy ===\n",
      "Final answer: The mean of the array is 3.0 and the standard deviation is 1.4142135623730951.\n",
      "\n",
      "=== Example 4: Inspecting Tool Calls ===\n",
      "Tool: python_repl_tool\n",
      "Arguments: {'code': 'import math\\nprint(math.factorial(10))'}\n",
      "Code executed: import math\n",
      "print(math.factorial(10))\n",
      "\n",
      "Final answer: 10 factorial is 3,628,800.\n",
      "\n",
      "=== Example 5: Error Handling ===\n",
      "Agent response: Dividing 10 by 0 results in a ZeroDivisionError in Python.\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "=== Streaming Example ===\n",
      "\n",
      "[agent] AIMessage\n",
      "  Tool calls: python_repl_tool\n",
      "\n",
      "[tools] ToolMessage\n",
      "  Content: ✓ Code executed successfully.\n",
      "Output:\n",
      "338350\n",
      "\n",
      "[agent] AIMessage\n",
      "  Content: The sum of squares from 1 to 100 is 338350.\n",
      "\n",
      "============================================================\n",
      "\n",
      "=== Code Extraction Example ===\n",
      "Code executed by agent: print(15 * 23)\n",
      "Final answer: 15 * 23 = 345\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example: Using python_repl_tool with create_react_agent\n",
    "\n",
    "This example demonstrates how to create a ReAct agent that can execute Python code\n",
    "to solve mathematical problems and perform data analysis tasks.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "from sparq.tools.python_repl.python_repl_tool import python_repl_tool\n",
    "from sparq.utils.helpers import get_llm\n",
    "from sparq.settings import Settings\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function demonstrating python_repl_tool usage with create_react_agent.\n",
    "    \n",
    "    Examples:\n",
    "        - Basic arithmetic\n",
    "        - Data analysis with libraries\n",
    "        - Multi-step calculations\n",
    "    \"\"\"\n",
    "    # Setup environment and LLM\n",
    "    settings = Settings()\n",
    "    settings._load_env_variables(Path(\".env\"))\n",
    "    \n",
    "    if not os.getenv(\"GEMINI_API_KEY\"):\n",
    "        raise ValueError(\"GEMINI_API_KEY is not set in the environment variables.\")\n",
    "    \n",
    "    llm = get_llm(model=\"gemini-2.0-flash\", provider=\"google_genai\")\n",
    "    \n",
    "    # Create ReAct agent with python_repl_tool\n",
    "    agent = create_react_agent(\n",
    "        model=llm,\n",
    "        tools=[python_repl_tool]\n",
    "    )\n",
    "    \n",
    "    # Example 1: Basic arithmetic\n",
    "    print(\"=== Example 1: Basic Arithmetic ===\")\n",
    "    result = agent.invoke({\n",
    "        \"messages\": [HumanMessage(content=\"Use Python to calculate 3.9345 + 5.4345\")]\n",
    "    })\n",
    "    print(f\"Final answer: {result['messages'][-1].content}\\n\")\n",
    "    \n",
    "    # Example 2: Multi-step calculation\n",
    "    print(\"=== Example 2: Multi-Step Calculation ===\")\n",
    "    result = agent.invoke({\n",
    "        \"messages\": [HumanMessage(\n",
    "            content=\"Calculate the average of these numbers: 12, 45, 67, 23, 89, 34\"\n",
    "        )]\n",
    "    })\n",
    "    print(f\"Final answer: {result['messages'][-1].content}\\n\")\n",
    "    \n",
    "    # Example 3: Data analysis with numpy\n",
    "    print(\"=== Example 3: Using NumPy ===\")\n",
    "    result = agent.invoke({\n",
    "        \"messages\": [HumanMessage(\n",
    "            content=\"Use numpy to create an array [1, 2, 3, 4, 5] and calculate its mean and standard deviation\"\n",
    "        )]\n",
    "    })\n",
    "    print(f\"Final answer: {result['messages'][-1].content}\\n\")\n",
    "    \n",
    "    # Example 4: Accessing tool call details\n",
    "    print(\"=== Example 4: Inspecting Tool Calls ===\")\n",
    "    result = agent.invoke({\n",
    "        \"messages\": [HumanMessage(content=\"Calculate 10 factorial using Python\")]\n",
    "    })\n",
    "    \n",
    "    # Find the AIMessage with tool calls\n",
    "    for message in result[\"messages\"]:\n",
    "        if hasattr(message, \"tool_calls\") and message.tool_calls:\n",
    "            for tool_call in message.tool_calls:\n",
    "                print(f\"Tool: {tool_call['name']}\")\n",
    "                print(f\"Arguments: {tool_call['args']}\")\n",
    "                print(f\"Code executed: {tool_call['args']['code']}\")\n",
    "                break\n",
    "    \n",
    "    print(f\"\\nFinal answer: {result['messages'][-1].content}\\n\")\n",
    "    \n",
    "    # Example 5: Handling errors gracefully\n",
    "    print(\"=== Example 5: Error Handling ===\")\n",
    "    result = agent.invoke({\n",
    "        \"messages\": [HumanMessage(\n",
    "            content=\"Try to divide 10 by 0 in Python\"\n",
    "        )]\n",
    "    })\n",
    "    print(f\"Agent response: {result['messages'][-1].content}\\n\")\n",
    "\n",
    "\n",
    "def stream_example():\n",
    "    \"\"\"\n",
    "    Example showing how to stream agent responses for real-time feedback.\n",
    "    \n",
    "    Note:\n",
    "        Streaming is useful for long-running calculations or when you want\n",
    "        to show progress to users.\n",
    "    \"\"\"\n",
    "    settings = Settings()\n",
    "    settings._load_env_variables(Path(\".env\"))\n",
    "    \n",
    "    llm = get_llm(model=\"gemini-2.0-flash\", provider=\"google_genai\")\n",
    "    agent = create_react_agent(model=llm, tools=[python_repl_tool])\n",
    "    \n",
    "    print(\"=== Streaming Example ===\")\n",
    "    prompt = \"Calculate the sum of squares from 1 to 100 using Python\"\n",
    "    \n",
    "    for chunk in agent.stream(\n",
    "        {\"messages\": [HumanMessage(content=prompt)]},\n",
    "        config={\"recursion_limit\": 10}\n",
    "    ):\n",
    "        # Print each step as it happens\n",
    "        for node_name, node_output in chunk.items():\n",
    "            if \"messages\" in node_output:\n",
    "                for msg in node_output[\"messages\"]:\n",
    "                    msg_type = type(msg).__name__\n",
    "                    print(f\"\\n[{node_name}] {msg_type}\")\n",
    "                    if hasattr(msg, \"content\") and msg.content:\n",
    "                        print(f\"  Content: {msg.content[:200]}\")\n",
    "                    if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
    "                        print(f\"  Tool calls: {msg.tool_calls[0]['name']}\")\n",
    "\n",
    "\n",
    "def extract_code_from_tool_call(agent_output: dict) -> str:\n",
    "    \"\"\"\n",
    "    Helper function to extract the Python code from tool calls in agent output.\n",
    "    \n",
    "    Args:\n",
    "        agent_output: Output dictionary from agent.invoke()\n",
    "        \n",
    "    Returns:\n",
    "        The Python code that was executed, or empty string if no tool calls found\n",
    "    \"\"\"\n",
    "    for message in agent_output[\"messages\"]:\n",
    "        if hasattr(message, \"tool_calls\") and message.tool_calls:\n",
    "            for tool_call in message.tool_calls:\n",
    "                if tool_call[\"name\"] == \"python_repl_tool\":\n",
    "                    return tool_call[\"args\"].get(\"code\", \"\")\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run basic examples\n",
    "    main()\n",
    "    \n",
    "    # Run streaming example\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "    stream_example()\n",
    "    \n",
    "    # Example of extracting code\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "    print(\"=== Code Extraction Example ===\")\n",
    "    \n",
    "    settings = Settings()\n",
    "    settings._load_env_variables(Path(\".env\"))\n",
    "    llm = get_llm(model=\"gemini-2.0-flash\", provider=\"google_genai\")\n",
    "    agent = create_react_agent(model=llm, tools=[python_repl_tool])\n",
    "    \n",
    "    result = agent.invoke({\n",
    "        \"messages\": [HumanMessage(content=\"Calculate 15 * 23 using Python\")]\n",
    "    })\n",
    "    \n",
    "    code = extract_code_from_tool_call(result)\n",
    "    print(f\"Code executed by agent: {code}\")\n",
    "    print(f\"Final answer: {result['messages'][-1].content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research-agentic-salmonella-langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
