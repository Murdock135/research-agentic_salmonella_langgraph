{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac163d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparq.tools.python_repl.python_repl_tool import python_repl_tool\n",
    "from sparq.utils.helpers import get_llm\n",
    "from sparq.settings import Settings\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ca71d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def my_tool_function(input: str) -> str:\n",
    "    \"\"\"\n",
    "    A simple tool function that processes the input string and returns a formatted string.\n",
    "    \"\"\"\n",
    "    return f\"Processed input: {input}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba2c49c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = Settings()\n",
    "settings._load_env_variables(Path(\"../.env\"))\n",
    "\n",
    "\n",
    "if os.getenv(\"GEMINI_API_KEY\"):\n",
    "    model = \"gemini-2.0-flash\"\n",
    "    provider = \"google_genai\"\n",
    "    llm = get_llm(model=model, provider=provider)\n",
    "else:\n",
    "    raise ValueError(\"GEMINI_API_KEY is not set in the environment variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d971a880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent created successfully with python REPL tool\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    agent = create_react_agent(\n",
    "        model=llm,\n",
    "        tools=[my_tool_function, python_repl_tool]\n",
    "    )\n",
    "    print(\"Agent created successfully with python REPL tool\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating agent: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05591153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent output: {'messages': [HumanMessage(content='Use python to add two numbers: 3.9345 and 5.4345', additional_kwargs={}, response_metadata={}, id='a62126e9-9970-49ec-b8cc-cbb4e30e4ca7'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'python_repl_tool', 'arguments': '{\"code\": \"print(3.9345 + 5.4345)\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--f21e11f9-98fa-46c6-b779-52d59cdbeb88-0', tool_calls=[{'name': 'python_repl_tool', 'args': {'code': 'print(3.9345 + 5.4345)'}, 'id': '9de84b79-44ef-489c-a20c-9c512a2babb3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 177, 'output_tokens': 23, 'total_tokens': 200, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='✓ Code executed successfully.\\nOutput:\\n9.369', name='python_repl_tool', id='7ad7fae7-b473-4da8-941a-6149536bb136', tool_call_id='9de84b79-44ef-489c-a20c-9c512a2babb3'), AIMessage(content='3.  9345 + 5.4345 = 9.369', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--4499c220-6510-40f7-88a5-525ab7894f7e-0', usage_metadata={'input_tokens': 220, 'output_tokens': 23, 'total_tokens': 243, 'input_token_details': {'cache_read': 0}})]}\n",
      "Type(output): <class 'langgraph.pregel.io.AddableValuesDict'>\n",
      "repr(output): {'messages': [HumanMessage(content='Use python to add two numbers: 3.9345 and 5.4345', additional_kwargs={}, response_metadata={}, id='a62126e9-9970-49ec-b8cc-cbb4e30e4ca7'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'python_repl_tool', 'arguments': '{\"code\": \"print(3.9345 + 5.4345)\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--f21e11f9-98fa-46c6-b779-52d59cdbeb88-0', tool_calls=[{'name': 'python_repl_tool', 'args': {'code': 'print(3.9345 + 5.4345)'}, 'id': '9de84b79-44ef-489c-a20c-9c512a2babb3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 177, 'output_tokens': 23, 'total_tokens': 200, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='✓ Code executed successfully.\\nOutput:\\n9.369', name='python_repl_tool', id='7ad7fae7-b473-4da8-941a-6149536bb136', tool_call_id='9de84b79-44ef-489c-a20c-9c512a2babb3'), AIMessage(content='3.  9345 + 5.4345 = 9.369', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--4499c220-6510-40f7-88a5-525ab7894f7e-0', usage_metadata={'input_tokens': 220, 'output_tokens': 23, 'total_tokens': 243, 'input_token_details': {'cache_read': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    prompt = \"Use python to add two numbers: 3.9345 and 5.4345\"\n",
    "    input = {\"messages\": [{\"role\": \"user\", \"content\": prompt}]}\n",
    "    output = agent.invoke(input)\n",
    "    print(f\"Agent output: {output}\")\n",
    "\n",
    "    print(\"Type(output):\", type(output))\n",
    "    print(\"repr(output):\", repr(output))\n",
    "except Exception as e:\n",
    "    print(f\"Error running agent: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "927cbc1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.369"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3.9345 + 5.4345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68b51135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "information on the output from agent.invoke()\n",
      "Type(output): <class 'langgraph.pregel.io.AddableValuesDict'>\n",
      "repr(output): {'messages': [HumanMessage(content='Use python to add two numbers: 3.9345 and 5.4345', additional_kwargs={}, response_metadata={}, id='a62126e9-9970-49ec-b8cc-cbb4e30e4ca7'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'python_repl_tool', 'arguments': '{\"code\": \"print(3.9345 + 5.4345)\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--f21e11f9-98fa-46c6-b779-52d59cdbeb88-0', tool_calls=[{'name': 'python_repl_tool', 'args': {'code': 'print(3.9345 + 5.4345)'}, 'id': '9de84b79-44ef-489c-a20c-9c512a2babb3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 177, 'output_tokens': 23, 'total_tokens': 200, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='✓ Code executed successfully.\\nOutput:\\n9.369', name='python_repl_tool', id='7ad7fae7-b473-4da8-941a-6149536bb136', tool_call_id='9de84b79-44ef-489c-a20c-9c512a2babb3'), AIMessage(content='3.  9345 + 5.4345 = 9.369', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--4499c220-6510-40f7-88a5-525ab7894f7e-0', usage_metadata={'input_tokens': 220, 'output_tokens': 23, 'total_tokens': 243, 'input_token_details': {'cache_read': 0}})]}\n",
      "len(output): 1\n",
      "output.keys(): dict_keys(['messages'])\n",
      "\n",
      "type(output['messages']): <class 'list'>\n",
      "len(output['messages']): 4\n",
      "[HumanMessage(content='Use python to add two numbers: 3.9345 and 5.4345', additional_kwargs={}, response_metadata={}, id='a62126e9-9970-49ec-b8cc-cbb4e30e4ca7'), AIMessage(content='', additional_kwargs={'function_call': {'name': 'python_repl_tool', 'arguments': '{\"code\": \"print(3.9345 + 5.4345)\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--f21e11f9-98fa-46c6-b779-52d59cdbeb88-0', tool_calls=[{'name': 'python_repl_tool', 'args': {'code': 'print(3.9345 + 5.4345)'}, 'id': '9de84b79-44ef-489c-a20c-9c512a2babb3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 177, 'output_tokens': 23, 'total_tokens': 200, 'input_token_details': {'cache_read': 0}}), ToolMessage(content='✓ Code executed successfully.\\nOutput:\\n9.369', name='python_repl_tool', id='7ad7fae7-b473-4da8-941a-6149536bb136', tool_call_id='9de84b79-44ef-489c-a20c-9c512a2babb3'), AIMessage(content='3.  9345 + 5.4345 = 9.369', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--4499c220-6510-40f7-88a5-525ab7894f7e-0', usage_metadata={'input_tokens': 220, 'output_tokens': 23, 'total_tokens': 243, 'input_token_details': {'cache_read': 0}})]\n",
      "\n",
      "type(output['messages'][0]): <class 'langchain_core.messages.human.HumanMessage'>\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Use python to add two numbers: 3.9345 and 5.4345\n",
      "output['messages'][0].pretty_print(): None\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  python_repl_tool (9de84b79-44ef-489c-a20c-9c512a2babb3)\n",
      " Call ID: 9de84b79-44ef-489c-a20c-9c512a2babb3\n",
      "  Args:\n",
      "    code: print(3.9345 + 5.4345)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"information on the output from agent.invoke()\")\n",
    "print(\"Type(output):\", type(output))\n",
    "print(\"repr(output):\", repr(output))\n",
    "print(\"len(output):\", len(output))\n",
    "print(\"output.keys():\", output.keys())\n",
    "print()\n",
    "print(\"type(output['messages']):\", type(output[\"messages\"]))\n",
    "print(\"len(output['messages']):\", len(output[\"messages\"]))\n",
    "print(output['messages'])\n",
    "print()\n",
    "print(\"type(output['messages'][0]):\", type(output[\"messages\"][0]))\n",
    "print(\"output['messages'][0].pretty_print():\", output['messages'][0].pretty_print())\n",
    "print()\n",
    "print(output['messages'][1].pretty_print())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a36ab6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_call': {'name': 'python_repl_tool',\n",
       "  'arguments': '{\"code\": \"print(3.9345 + 5.4345)\"}'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['messages'][1].additional_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84e2378e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"code\": \"print(3.9345 + 5.4345)\"}'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['messages'][1].additional_kwargs['function_call']['arguments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31df962c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 'print(3.9345 + 5.4345)'}\n",
      "print(3.9345 + 5.4345)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.loads(output['messages'][1].additional_kwargs['function_call']['arguments']))\n",
    "\n",
    "# get the code\n",
    "code = json.loads(output['messages'][1].additional_kwargs['function_call']['arguments'])['code']\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "071ef1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process worked: Hello from subprocess\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic: Test basic multiprocessing\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "def simple_test(queue):\n",
    "    queue.put(\"Hello from subprocess\")\n",
    "\n",
    "queue = mp.Queue()\n",
    "process = mp.Process(target=simple_test, args=(queue,))\n",
    "process.start()\n",
    "process.join(timeout=5)\n",
    "\n",
    "if process.is_alive():\n",
    "    print(\"Process hung!\")\n",
    "    process.terminate()\n",
    "else:\n",
    "    result = queue.get()\n",
    "    print(f\"Process worked: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b6adf23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing basic function call...\n",
      "Success: ✗ Execution failed.\n",
      "Error (QueueEmptyError): Result queue was empty.\n",
      "\n",
      "Traceback:\n",
      "\n",
      "Extra Context:\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Test basic function\n",
    "print(\"Testing basic function call...\")\n",
    "code = \"\"\"\n",
    "def foo(x: int) -> int:\n",
    "    return x + x\n",
    "\n",
    "x = 3\n",
    "print(foo(x))\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    result = python_repl_tool.invoke({\"code\": code, \"timeout\": 5})\n",
    "    print(f\"Success: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0afb2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Recursion with Fibonacci...\n",
      "Success: ✗ Execution failed.\n",
      "Error (QueueEmptyError): Result queue was empty.\n",
      "\n",
      "Traceback:\n",
      "\n",
      "Extra Context:\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Test Fibonacci\n",
    "from sparq.tools.python_repl.python_repl_tool import python_repl_tool\n",
    "\n",
    "print(\"Testing Recursion with Fibonacci...\")\n",
    "code = \"\"\"\n",
    "def fib(n):\n",
    "    if n <= 0:\n",
    "        return 0\n",
    "    elif n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return fib(n-1) + fib(n-2)\n",
    "\n",
    "print(f\"fib(10): {fib(10)}\")\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    result = python_repl_tool.invoke({\"code\": code, \"timeout\": 30})\n",
    "    print(f\"Success: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6afdc050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Recursion with Fibonacci...\n",
      "Success: ✗ Execution failed.\n",
      "Error (QueueEmptyError): Result queue was empty.\n",
      "\n",
      "Traceback:\n",
      "\n",
      "Extra Context:\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Test Fibonacci\n",
    "from sparq.tools.python_repl.python_repl_tool import python_repl_tool\n",
    "\n",
    "print(\"Testing Recursion with Fibonacci...\")\n",
    "code = \"\"\"\n",
    "def fib(n):\n",
    "    if n <= 0:\n",
    "        return 0\n",
    "    elif n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return fib(n-1) + fib(n-2)\n",
    "\n",
    "print(f\"fib(10): {fib(10)}\")\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    result = python_repl_tool.invoke({\"code\": code, \"timeout\": 30})\n",
    "    print(f\"Success: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29ca3fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing NumPy execution directly...\n",
      "Success: ✗ Execution failed.\n",
      "Error (QueueEmptyError): Result queue was empty.\n",
      "\n",
      "Traceback:\n",
      "\n",
      "Extra Context:\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Test NumPy with detailed output\n",
    "from sparq.tools.python_repl.python_repl_tool import python_repl_tool\n",
    "\n",
    "print(\"Testing NumPy execution directly...\")\n",
    "code = \"\"\"\n",
    "import numpy as np\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "mean = arr.mean()\n",
    "std = arr.std()\n",
    "print(f\"Mean: {mean}, Std: {std}\")\n",
    "mean\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    result = python_repl_tool.invoke({\"code\": code, \"timeout\": 30})\n",
    "    print(f\"Success: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "383a3e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Example 1: Basic Arithmetic ===\n",
      "Final answer: 3.  9345 + 5.4345 = 9.369\n",
      "\n",
      "=== Example 2: Multi-Step Calculation ===\n",
      "Final answer: The average of the numbers is 45.0.\n",
      "\n",
      "=== Example 3: Using NumPy ===\n"
     ]
    },
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mGraphRecursionError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 148\u001b[39m\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    147\u001b[39m     \u001b[38;5;66;03m# Run basic examples\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m     \u001b[38;5;66;03m# Run streaming example\u001b[39;00m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 61\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# Example 3: Data analysis with numpy\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== Example 3: Using NumPy ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m result = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mUse numpy to create an array [1, 2, 3, 4, 5] and calculate its mean and standard deviation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFinal answer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m].content\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# Example 4: Accessing tool call details\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/mine/research-agentic_salmonella_langgraph/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2894\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2891\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] = []\n\u001b[32m   2892\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2894\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2895\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2896\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2897\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2898\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2899\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2900\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2901\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2902\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2903\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2904\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2905\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2906\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2907\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2908\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mints\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINTERRUPT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   2909\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/code/mine/research-agentic_salmonella_langgraph/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2547\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m loop.status == \u001b[33m\"\u001b[39m\u001b[33mout_of_steps\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2539\u001b[39m     msg = create_error_message(\n\u001b[32m   2540\u001b[39m         message=(\n\u001b[32m   2541\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[33m'\u001b[39m\u001b[33mrecursion_limit\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m reached \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2545\u001b[39m         error_code=ErrorCode.GRAPH_RECURSION_LIMIT,\n\u001b[32m   2546\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2547\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(msg)\n\u001b[32m   2548\u001b[39m \u001b[38;5;66;03m# set final channel values as run output\u001b[39;00m\n\u001b[32m   2549\u001b[39m run_manager.on_chain_end(loop.output)\n",
      "\u001b[31mGraphRecursionError\u001b[39m: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example: Using python_repl_tool with create_react_agent\n",
    "\n",
    "This example demonstrates how to create a ReAct agent that can execute Python code\n",
    "to solve mathematical problems and perform data analysis tasks.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "from sparq.tools.python_repl.python_repl_tool import python_repl_tool\n",
    "from sparq.utils.helpers import get_llm\n",
    "from sparq.settings import Settings\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function demonstrating python_repl_tool usage with create_react_agent.\n",
    "    \n",
    "    Examples:\n",
    "        - Basic arithmetic\n",
    "        - Data analysis with libraries\n",
    "        - Multi-step calculations\n",
    "    \"\"\"\n",
    "    # Setup environment and LLM\n",
    "    settings = Settings()\n",
    "    settings._load_env_variables(Path(\".env\"))\n",
    "    \n",
    "    if not os.getenv(\"GEMINI_API_KEY\"):\n",
    "        raise ValueError(\"GEMINI_API_KEY is not set in the environment variables.\")\n",
    "    \n",
    "    llm = get_llm(model=\"gemini-2.0-flash\", provider=\"google_genai\")\n",
    "    \n",
    "    # Create ReAct agent with python_repl_tool\n",
    "    agent = create_react_agent(\n",
    "        model=llm,\n",
    "        tools=[python_repl_tool]\n",
    "    )\n",
    "    \n",
    "    # Example 1: Basic arithmetic\n",
    "    print(\"=== Example 1: Basic Arithmetic ===\")\n",
    "    result = agent.invoke({\n",
    "        \"messages\": [HumanMessage(content=\"Use Python to calculate 3.9345 + 5.4345\")]\n",
    "    })\n",
    "    print(f\"Final answer: {result['messages'][-1].content}\\n\")\n",
    "    \n",
    "    # Example 2: Multi-step calculation\n",
    "    print(\"=== Example 2: Multi-Step Calculation ===\")\n",
    "    result = agent.invoke({\n",
    "        \"messages\": [HumanMessage(\n",
    "            content=\"Calculate the average of these numbers: 12, 45, 67, 23, 89, 34\"\n",
    "        )]\n",
    "    })\n",
    "    print(f\"Final answer: {result['messages'][-1].content}\\n\")\n",
    "    \n",
    "    # Example 3: Data analysis with numpy\n",
    "    print(\"=== Example 3: Using NumPy ===\")\n",
    "    result = agent.invoke({\n",
    "        \"messages\": [HumanMessage(\n",
    "            content=\"Use numpy to create an array [1, 2, 3, 4, 5] and calculate its mean and standard deviation\"\n",
    "        )]\n",
    "    })\n",
    "    print(f\"Final answer: {result['messages'][-1].content}\\n\")\n",
    "    \n",
    "    # Example 4: Accessing tool call details\n",
    "    print(\"=== Example 4: Inspecting Tool Calls ===\")\n",
    "    result = agent.invoke({\n",
    "        \"messages\": [HumanMessage(content=\"Calculate 10 factorial using Python\")]\n",
    "    })\n",
    "    \n",
    "    # Find the AIMessage with tool calls\n",
    "    for message in result[\"messages\"]:\n",
    "        if hasattr(message, \"tool_calls\") and message.tool_calls:\n",
    "            for tool_call in message.tool_calls:\n",
    "                print(f\"Tool: {tool_call['name']}\")\n",
    "                print(f\"Arguments: {tool_call['args']}\")\n",
    "                print(f\"Code executed: {tool_call['args']['code']}\")\n",
    "                break\n",
    "    \n",
    "    print(f\"\\nFinal answer: {result['messages'][-1].content}\\n\")\n",
    "    \n",
    "    # Example 5: Handling errors gracefully\n",
    "    print(\"=== Example 5: Error Handling ===\")\n",
    "    result = agent.invoke({\n",
    "        \"messages\": [HumanMessage(\n",
    "            content=\"Try to divide 10 by 0 in Python\"\n",
    "        )]\n",
    "    })\n",
    "    print(f\"Agent response: {result['messages'][-1].content}\\n\")\n",
    "\n",
    "\n",
    "def stream_example():\n",
    "    \"\"\"\n",
    "    Example showing how to stream agent responses for real-time feedback.\n",
    "    \n",
    "    Note:\n",
    "        Streaming is useful for long-running calculations or when you want\n",
    "        to show progress to users.\n",
    "    \"\"\"\n",
    "    settings = Settings()\n",
    "    settings._load_env_variables(Path(\".env\"))\n",
    "    \n",
    "    llm = get_llm(model=\"gemini-2.0-flash\", provider=\"google_genai\")\n",
    "    agent = create_react_agent(model=llm, tools=[python_repl_tool])\n",
    "    \n",
    "    print(\"=== Streaming Example ===\")\n",
    "    prompt = \"Calculate the sum of squares from 1 to 100 using Python\"\n",
    "    \n",
    "    for chunk in agent.stream(\n",
    "        {\"messages\": [HumanMessage(content=prompt)]},\n",
    "        config={\"recursion_limit\": 10}\n",
    "    ):\n",
    "        # Print each step as it happens\n",
    "        for node_name, node_output in chunk.items():\n",
    "            if \"messages\" in node_output:\n",
    "                for msg in node_output[\"messages\"]:\n",
    "                    msg_type = type(msg).__name__\n",
    "                    print(f\"\\n[{node_name}] {msg_type}\")\n",
    "                    if hasattr(msg, \"content\") and msg.content:\n",
    "                        print(f\"  Content: {msg.content[:200]}\")\n",
    "                    if hasattr(msg, \"tool_calls\") and msg.tool_calls:\n",
    "                        print(f\"  Tool calls: {msg.tool_calls[0]['name']}\")\n",
    "\n",
    "\n",
    "def extract_code_from_tool_call(agent_output: dict) -> str:\n",
    "    \"\"\"\n",
    "    Helper function to extract the Python code from tool calls in agent output.\n",
    "    \n",
    "    Args:\n",
    "        agent_output: Output dictionary from agent.invoke()\n",
    "        \n",
    "    Returns:\n",
    "        The Python code that was executed, or empty string if no tool calls found\n",
    "    \"\"\"\n",
    "    for message in agent_output[\"messages\"]:\n",
    "        if hasattr(message, \"tool_calls\") and message.tool_calls:\n",
    "            for tool_call in message.tool_calls:\n",
    "                if tool_call[\"name\"] == \"python_repl_tool\":\n",
    "                    return tool_call[\"args\"].get(\"code\", \"\")\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run basic examples\n",
    "    main()\n",
    "    \n",
    "    # Run streaming example\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "    stream_example()\n",
    "    \n",
    "    # Example of extracting code\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "    print(\"=== Code Extraction Example ===\")\n",
    "    \n",
    "    settings = Settings()\n",
    "    settings._load_env_variables(Path(\".env\"))\n",
    "    llm = get_llm(model=\"gemini-2.0-flash\", provider=\"google_genai\")\n",
    "    agent = create_react_agent(model=llm, tools=[python_repl_tool])\n",
    "    \n",
    "    result = agent.invoke({\n",
    "        \"messages\": [HumanMessage(content=\"Calculate 15 * 23 using Python\")]\n",
    "    })\n",
    "    \n",
    "    code = extract_code_from_tool_call(result)\n",
    "    print(f\"Code executed by agent: {code}\")\n",
    "    print(f\"Final answer: {result['messages'][-1].content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research-agentic-salmonella-langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
